{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "_FIELD_NAMES = [\n",
    "    'song_title',\n",
    "    'song_hash',\n",
    "    'song_difficulty',\n",
    "    'song_meter',\n",
    "    'members_name',\n",
    "    'score',\n",
    "    'lamp'\n",
    "]\n",
    "\n",
    "song_hash_chars = {}\n",
    "\n",
    "src = '3ic_data/3ic_data_20220805.csv'\n",
    "with open(src, 'r', encoding='utf-8') as fp:\n",
    "    reader = csv.DictReader(fp, fieldnames=_FIELD_NAMES)\n",
    "    for row in reader:\n",
    "        for c in row['song_hash']:\n",
    "            if c in song_hash_chars:\n",
    "                song_hash_chars[c] += 1\n",
    "            else:\n",
    "                song_hash_chars[c] = 0\n",
    "\n",
    "print(len(song_hash_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in sorted(song_hash_chars):\n",
    "    print(f'{c:3s} {ord(c):3d} 0x{ord(c):02X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a8e(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s2 = [c for c in s.lower() if (c >= 'a' and c <= 'z') or (c >= '0' and c <= '9')]\n",
    "    l = len(s2)\n",
    "    return f'{s[0]}{l-2}{s[-1]}'\n",
    "\n",
    "for t in ['Puberty Dysthymia', 'Cytokinesis', 'Dance Dance Revolution']:\n",
    "    print(a8e(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [chr(v + ord('A')) for v in range(5)]\n",
    "\n",
    "load_order = []\n",
    "\n",
    "for i_row, a in enumerate(v):\n",
    "    tri = v[i_row:]\n",
    "    if i_row % 2 == 1:\n",
    "         tri.reverse()\n",
    "    for i_col, b in enumerate(tri):\n",
    "        load_order.append( (a, b) )\n",
    "\n",
    "load_replacement = [load_order[0]]\n",
    "for prev, next in zip(load_order[:-1], load_order[1:]):\n",
    "    repl = [a != b and b or None for a, b in zip(prev, next)]\n",
    "    load_replacement.append(tuple(repl))\n",
    "\n",
    "print(load_replacement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PARTITION_SIZE = 3\n",
    "_TOTAL_LENGTH = 26\n",
    "_EXCLUDE_DIAGONAL = True\n",
    "_EXPLICIT_PAIRS = False\n",
    "\n",
    "v = [chr(v + ord('A')) for v in range(_TOTAL_LENGTH)]\n",
    "v_part = [v[i:i+_PARTITION_SIZE] for i in range(0, _TOTAL_LENGTH, _PARTITION_SIZE)]\n",
    "print(v_part)\n",
    "\n",
    "load_order = []\n",
    "\n",
    "load_replacement = []\n",
    "exc_diag = _EXCLUDE_DIAGONAL and 1 or 0\n",
    "for i_row in range(0, len(v_part), 2):\n",
    "    # (i, i) --> (i, n)\n",
    "    for i_col in range(i_row + exc_diag, len(v_part)):\n",
    "        if _EXPLICIT_PAIRS or (i_col == i_row + exc_diag):\n",
    "            load_replacement.append( (i_row, i_col) )\n",
    "        else:\n",
    "            load_replacement.append( (None, i_col) )\n",
    "\n",
    "    # (i+1, i+1) <-- (i+1, n)\n",
    "    if i_row + 1 >= len(v_part):\n",
    "        break\n",
    "    for i_col in range(len(v_part) - 1, i_row + exc_diag, -1):\n",
    "        if i_col == len(v_part) - 1:\n",
    "            load_replacement.append( (i_row + 1, _EXPLICIT_PAIRS and i_col or None) )\n",
    "        else:\n",
    "            load_replacement.append( (_EXPLICIT_PAIRS and (i_row + 1) or None, i_col) )\n",
    "\n",
    "print(load_replacement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def timestamp():\n",
    "    return dt.utcnow().strftime('%Y%m%d-%H%M%S-%f')[:-3]\n",
    "p = os.path.join('itl2023_data', dt.utcnow().strftime('%Y%m%d'))\n",
    "\n",
    "# Set up logging\n",
    "logging.getLogger().handlers.clear()\n",
    "log_stamp = timestamp()\n",
    "log_path = os.path.join(p, f'scobility-scrape-{log_stamp}.log')\n",
    "log_fmt = logging.Formatter(\n",
    "    '[%(asctime)s.%(msecs)03d] %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logging.basicConfig(\n",
    "    filename=log_path,\n",
    "    encoding='utf-8',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n",
    "for handler in logging.getLogger().handlers:\n",
    "    handler.setFormatter(log_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart query\n",
    "charts = {}\n",
    "strikes = []\n",
    "for i in range(10000):\n",
    "    r = requests.get(f'https://itl2023.groovestats.com/api/chart/{i}')\n",
    "    j = r.json()\n",
    "    if not j.get('success', False):\n",
    "        logging.warning(f\"{i:4d}: {j.get('message', '')}\")\n",
    "        strikes.append(i)\n",
    "        if len(strikes) > 5:\n",
    "            break\n",
    "    else:\n",
    "        strikes = []\n",
    "        charts[i] = j.get('data', {})\n",
    "        full_name = f\"{charts[i].get('artist')} - \\\"{charts[i].get('title')}\\\"\"\n",
    "        logging.info(f'{i:4d}: {full_name}')\n",
    "\n",
    "if not os.path.exists(p):\n",
    "    os.makedirs(p)\n",
    "with open(os.path.join(p, 'charts.json'), 'w', encoding='utf-8') as fp:\n",
    "    json.dump(charts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_entrants = os.path.join(p, 'entrant_info')\n",
    "if not os.path.exists(p_entrants):\n",
    "    os.makedirs(p_entrants)\n",
    "\n",
    "# Entrant query\n",
    "entrants = {}\n",
    "strikes = []\n",
    "for i in range(10000):\n",
    "    r = requests.get(f'https://itl2023.groovestats.com/api/entrant/{i}')\n",
    "    j = r.json()\n",
    "    if not j.get('success', False):\n",
    "        logging.warning(f\"{i:4d}: {j.get('message', '')}\")\n",
    "        strikes.append(i)\n",
    "        if len(strikes) > 5:\n",
    "            break\n",
    "    else:\n",
    "        strikes = []\n",
    "        entrants[i] = j.get('data', {})\n",
    "        full_name = f\"{entrants[i]['entrant']['name']} (ITL #{entrants[i]['entrant']['id']}, GS #{entrants[i]['entrant']['membersId']})\"\n",
    "        logging.info(f'{i:4d}: {full_name}')\n",
    "\n",
    "        with open(os.path.join(p_entrants, f'{i}.json'), 'w', encoding='utf-8') as fp:\n",
    "            json.dump(entrants[i], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_scores = os.path.join(p, 'song_scores')\n",
    "if not os.path.exists(p_scores):\n",
    "    os.makedirs(p_scores)\n",
    "\n",
    "with open(os.path.join(p, 'charts.json'), 'r', encoding='utf-8') as fp:\n",
    "    charts = json.load(fp)\n",
    "\n",
    "# Entrant query\n",
    "scores = {}\n",
    "strikes = []\n",
    "total = 0\n",
    "for c in charts.values():\n",
    "    total += 1\n",
    "    if total > 10000:\n",
    "        break\n",
    "\n",
    "    i = c.get('id', 0)\n",
    "\n",
    "    r = requests.post(\n",
    "        f'https://itl2023.groovestats.com/api/score/chartTopScores',\n",
    "        data={'chartHash': c['hash']}\n",
    "    )\n",
    "    j = r.json()\n",
    "    if not j.get('success', False):\n",
    "        logging.warning(f\"{i:4d} (hash {c['hash']}): {j.get('message', '')}\")\n",
    "        strikes.append(i)\n",
    "        if len(strikes) > 5:\n",
    "            break\n",
    "    else:\n",
    "        strikes = []\n",
    "        full_name = f\"{c.get('artist')} - \\\"{c.get('title')}\\\"\"\n",
    "        scores[i] = j.get('data', {}).get('leaderboard', {})\n",
    "        for s in scores[i]:\n",
    "            s['chartId'] = i\n",
    "        logging.info(f\"{i:4d} (hash {c['hash']}): {full_name}, {len(scores[i])} scores\")\n",
    "\n",
    "        with open(os.path.join(p_scores, f'{i}.json'), 'w', encoding='utf-8') as fp:\n",
    "            json.dump({'scores': scores[i]}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_charts = os.path.join(p, 'song_info')\n",
    "if not os.path.exists(p_charts):\n",
    "    os.makedirs(p_charts)\n",
    "\n",
    "with open(os.path.join(p, 'charts.json'), 'r', encoding='utf-8') as fp:\n",
    "    charts = json.load(fp)\n",
    "\n",
    "for c in charts.values():\n",
    "    i = c.get('id', 0)\n",
    "    \n",
    "    full_name = f\"{c.get('artist')} - \\\"{c.get('title')}\\\"\"\n",
    "    logging.info(f\"{i:4d} (hash {c['hash']}): {full_name}\")\n",
    "\n",
    "    with open(os.path.join(p_charts, f'{i}.json'), 'w', encoding='utf-8') as fp:\n",
    "        json.dump({'song': c}, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d37f3fb7e44e5043151cfeeeeb26c4dc1eced2e6e128533299704562dd693bb2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('scobility-Dqmn35Dz': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
